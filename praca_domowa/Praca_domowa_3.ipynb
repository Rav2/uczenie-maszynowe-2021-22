{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3oQCP6SxCgVr"
   },
   "source": [
    "# Rozpoznawanie obrazu na potrzeby eksperymentu naukowego"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_eXe3NynCgWL"
   },
   "source": [
    "Pi of the Sky (https://www.pi.fuw.edu.pl/jest) jest eksperymentem astrofizycznym, którego głównym celem jest poszukiwanie rozbłysków gamma (GRB) (https://pl.wikipedia.org/wiki/Rozbłysk_gamma). W tym celu zautomatyzowane teleskopy w Chile i Hiszpanii fotografują niebo w poszukiwaniu interesujących zdarzeń. Klasyczne algorytmy wykrywania rozbłysków gamma działają w następujący sposób: wybrany obszar nieba jest stale fotografowany w pewnych odstępach czasu, jeżeli skanowany obszar zmieni się w jakiś sposób, może to oznaczać, iż pojawiło się nowe źródło promieniowania, dlatego kilka(naście) klatek (zdjęć) przed i po wystąpieniu zjawiska jest zachowywanych do późniejszej analizy. Naukowcy analizują sekwencję zdjęć aby stwierdzić, czy faktycznie zaobserwowano rozbłysk gamma. Niestety, wiele spośród zebranych danych to fałszywe alarmy, wywołane np. przez chmury poruszające się na niebie. Celem niniejszego ćwiczenia jest stworzenie algorytmu uczenia maszynowego opartego o konwolucyjne sieci neuronowe, który mógłby usprawnić analizę poprzez odsiewanie niepoprawnych danych, oszczędzając pracy naukowcom.\n",
    "\n",
    "W zadaniu chcemy stworzyć tzw. \"proof of concept\", czyli rozwiązanie dalekie od ostatecznego, ale pokazujące, że problem może potencjalnie zostać rozwiązany z użyciem zaproponowanej metody. Ograniczymy się do analizy pojedynczych obrazów a nie całych sekwencji. Chcemy dokonać klasyfikacji obrazów należących do trzech klas:\n",
    "\n",
    "0) zdjęcia potencjalnie zawierające rozbłyski gamma \n",
    "\n",
    "1) fałszywe alarmy przedstawiające niebo z chmurami\n",
    "\n",
    "2) fałszywe alarmy zawierające artefakty spowodowane wadliwą pracą aparatury badawczej (poziome/pionowe linie)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qbk-GTQMCgWN"
   },
   "source": [
    " ## Polecenia\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y9tXgvpSCgWQ"
   },
   "source": [
    "#### Uwaga ogólna: Wszystkie wykresy i obrazki w notatniku mają być estetyczne, zawierać podpisy osi, tytuły, legendy itp. Wypisując jakieś wartości należy napisać również czym one są. Przed wysłaniem rozwiązania należy usunąć wszystkie niepotrzebne komentarze i komórki. Mile widziane są opisy/komentarze wyjaśniające co w danej komórce próbujecie zrobić.\n",
    "\n",
    "1. Wczytanie i wstępna obróbka danych\n",
    "     * Proszę pobrać archiwum \"data.zip\":\n",
    "     https://github.com/Rav2/uczenie-maszynowe-2021-22/raw/main/praca_domowa/data.zip\n",
    "     * Archiwum należy rozpakować. Folder \"data\" zawiera trzy podfoldery odpowiadające trzem klasom: \"0\", \"1\" oraz \"2\", które zawierają obrazki w formacie JPG. Wszystkie obrazki mają identyczne wymiary. Jeśli chcecie pracować w Google Collab, to polecam przesłać obrazki na dysk Google i podłączyć ten dysk do notebooka (instrukcja niżej).\n",
    "     * Proszę wczytać obrazki, np. korzystając z funkcji\n",
    "     tensorflow.keras.preprocessing.image.load_img (patrz przykład poniżej) i stworzyć tensor cech X i wektor etykiet y.\n",
    "     * Tensor cech powinnien mieć wymiar (3573, 100, 100, 1). 1 odpowiada pojedynczemu kanałowi (czarno-biały obraz). Jeżeli dane nie mają takiego kształtu to proszę im go nadać.\n",
    "     * Proszę sprawdzić i wyświetlić liczebność klas.\n",
    "     * Proszę sprawdzić i wyświetlić wymiary obrazka (w pikselach) i zapisać do zmiennych. Przydadzą się później.\n",
    "     * Proszę wyświetlić po jednym obrazku z każdej klasy wraz z numerem klasy.\n",
    "2. Preprocessing\n",
    "     * Proszę przeskalować wartości pikseli tak, żeby były w przedziale [0,1].\n",
    "     * Proszę podzielić dane na zbiory uczący (70%) i testowy (30%).\n",
    "     * Proszę sprawdzić, czy rozkład klas w obu zbiorach jest zbliżony. Jeżeli nie jest, to proszę dokonać podziału danych tak, żeby był.\n",
    "3. Uczenie sieci\n",
    "    * Proszę zaproponować architekturę sieci opartą o warstwy CNN. Proszę wykorzystać również pooling oraz dropout i pamiętać o spłaszczeniu na końcu. Sieć ma przyjmować obrazki w oryginalnych rozmiarach. Proszę pamiętać o właściwej funkcji aktywacji w ostatniej warstwie.\n",
    "    * Proszę wytrenować sieć wydzielając ze zbioru uczącego 15% na walidację.\n",
    "    * Proszę narysować wykresy accuracy i funkcji kosztu w funkcji numeru epoki (iteracji) uczenia, zarówno dla zbioru uczącego jak i walidacyjnego.\n",
    "4. Ewaluacja\n",
    "    * Proszę dokonać predykcji na zbiorze testowym.\n",
    "    * Proszę wypisać raport z klasyfikacji i macierz pomyłek. W przypadku otrzymania mniej niż 80% accuracy proszę porawić architekturę i parametry sieci.\n",
    "    * Proszę policzyć procent poprawnie sklasyfikowanych obrazków dla każdej z klas i przedstawić na histogramie.\n",
    "    * Proszę narysować wykres ROC i podać pole wykresu pod krzywą. \n",
    "5. Generacja pseudodanych\n",
    "  * Proszę zapoznać się z dokumentacją klasy tensorflow.keras.preprocessing.image.ImageDataGenerator oraz przykładami użycia.\n",
    "  * Proszę stworzyć obiekt typu ImageDataGenerator z parametrami pozwalającymi na generację pseudodanych poprzez użycie:\n",
    "    a) przesunięcia o nie wiecej niż 20 pikseli\n",
    "    b) odbicia względem osi OX lub OY\n",
    "    c) zoom do 10%\n",
    "  * Proszę przeznaczyć 15% zbioru treningowego na zbiór walidacyjny.\n",
    "  * Korzystając z metody \"flow\" dla obiektu typu ImageDataGenerator proszę wytrenować sieć neuronową.\n",
    "  * Proszę przeprowadzić ponowną ewaluację sieci wytrenowanej z generacją pseudodanych.\n",
    "  *Proszę porównać wyniki z wcześniejszymi i napisać kilka zdań komentarza z wyjaśnieniem obecności lub braku różnic.\n",
    "\n",
    "6. Dodatkowe (dla chętnych)\n",
    "    * Znaleźć optymalne wartości hiperparametrów sieci w sposób automatyczny, wykorzystując jedną z dostępnych bibliotek lub implementując samemu, np. z użyciem zagnieżdżonych pętli for.\n",
    "    * Dla znalezionych parametrów wykonać uczenie i ewaluację. Porównać z wcześniejszymi wynikami."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pobranie danych i rozpakowanie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Odkomentuj i wykonaj, żeby pobrać dane i rozpakować\n",
    "#! wget https://github.com/Rav2/uczenie-maszynowe-2021-22/raw/main/praca_domowa/data.zip\n",
    "#! unzip -q data.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Podpięcie dysku Google do notebooka (po tym wszystkie pliki na dysku będą dostępne, trzeba zatwierdzić w wyskakujących okienkach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KNaRjaP3CqBB",
    "outputId": "ce40c124-2eda-4cc6-8624-9b084b958d1e"
   },
   "outputs": [],
   "source": [
    "# Jeżeli chcesz/potrzebujesz udostępnić swój dysk Google notatnikowi z Collaba to możesz to zrobić następująco.\n",
    "# Odkomentuj i wykonaj, żeby podłączyć swój dysk Google do notatnika\n",
    "# Pliki będą dostępne pod ścieżką /content/drive/...\n",
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xYYH6THsCgWh"
   },
   "source": [
    "#### przykład wczytania obrazka nr 5 z folderu 'data/1/' i konwersji do numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "n35ri67zCgWi"
   },
   "outputs": [],
   "source": [
    "#  import os\n",
    "#  from tensorflow.keras.preprocessing.image import load_img\n",
    "\n",
    "## Sprawdź jakie pliki są w folderze\n",
    "#  files = os.listdir('data/1/')\n",
    " \n",
    "## Ustal pełną ścieżkę do pliku nr 5\n",
    "#  path = os.path.join('data/1/', files[5])\n",
    " \n",
    "## Wczytaj obrazek\n",
    "#  img = load_img(path, color_mode='grayscale')\n",
    " \n",
    "## Przekonwertuj do tablicy w numpy\n",
    "#  img_arr = np.asarray(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w4vs2HlGCgWv"
   },
   "source": [
    "# Rozwiązanie"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Praca_domowa_3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
